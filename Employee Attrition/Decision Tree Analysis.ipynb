{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>Division</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  satisfaction_level  last_evaluation  number_project  \\\n",
       "0   1                0.38             0.53               2   \n",
       "1   2                0.80             0.86               5   \n",
       "2   3                0.11             0.88               7   \n",
       "3   4                0.72             0.87               5   \n",
       "4   5                0.37             0.52               2   \n",
       "\n",
       "   average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "0                   157                   3              0     1   \n",
       "1                   262                   6              0     1   \n",
       "2                   272                   4              0     1   \n",
       "3                   223                   5              0     1   \n",
       "4                   159                   3              0     1   \n",
       "\n",
       "   promotion_last_5years Division  salary  \n",
       "0                      0    sales     low  \n",
       "1                      0    sales  medium  \n",
       "2                      0    sales  medium  \n",
       "3                      0    sales     low  \n",
       "4                      0    sales     low  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"Why are employees leaving.csv\")  #Loading file into my Notebook\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate entropy based on the 'left' column\n",
    "import math\n",
    "\n",
    "def calculate_entropy(data, target_column):\n",
    "    \"\"\"\n",
    "    Calculate entropy for a given target column\n",
    "    Entropy = -Σ(p * log2(p)) where p is the probability of each class\n",
    "    \"\"\"\n",
    "    # Get value counts and probabilities\n",
    "    value_counts = data[target_column].value_counts()\n",
    "    total_samples = len(data)\n",
    "    \n",
    "    entropy = 0\n",
    "    # print(f\"Distribution of '{target_column}' column:\")\n",
    "    # print(f\"Total samples: {total_samples}\")\n",
    "    \n",
    "    for value, count in value_counts.items():\n",
    "        probability = count / total_samples\n",
    "        if probability > 0:  # Avoid log(0)\n",
    "            entropy -= probability * math.log2(probability)\n",
    "        # print(f\"  {target_column}={value}: {count} samples ({probability:.4f} probability)\")\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "# Calculate entropy for the 'left' column\n",
    "entropy_left = calculate_entropy(df, 'left')\n",
    "# print(f\"\\n Baseline Entropy of the dataset based on 'left' column: {entropy_left:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n================================================================================\n",
      "=== INFORMATION GAIN ANALYSIS FOR 'DIVISION' COLUMN ===\n",
      "\n",
      "\n",
      "1. BASELINE ENTROPY of 'left' column: 0.7918\n",
      "\n",
      "2. UNIQUE VALUES in 'Division' column: ['sales' 'accounting' 'hr' 'technical' 'support' 'management' 'IT'\n",
      " 'product_mng' 'marketing' 'RandD']\n",
      "\n",
      "3. CALCULATING ENTROPY FOR EACH SUBSET:\n",
      "--------------------------------------------------\n",
      "\\n  Subset: Division='sales'\n",
      "  - Size: 4140 samples (0.2760 of total)\n",
      "  - Entropy: 0.8031\n",
      "  - Weighted contribution: 0.2760 × 0.8031 = 0.2217\n",
      "\\n  Subset: Division='accounting'\n",
      "  - Size: 767 samples (0.0511 of total)\n",
      "  - Entropy: 0.8356\n",
      "  - Weighted contribution: 0.0511 × 0.8356 = 0.0427\n",
      "\\n  Subset: Division='hr'\n",
      "  - Size: 739 samples (0.0493 of total)\n",
      "  - Entropy: 0.8699\n",
      "  - Weighted contribution: 0.0493 × 0.8699 = 0.0429\n",
      "\\n  Subset: Division='technical'\n",
      "  - Size: 2720 samples (0.1813 of total)\n",
      "  - Entropy: 0.8210\n",
      "  - Weighted contribution: 0.1813 × 0.8210 = 0.1489\n",
      "\\n  Subset: Division='support'\n",
      "  - Size: 2229 samples (0.1486 of total)\n",
      "  - Entropy: 0.8097\n",
      "  - Weighted contribution: 0.1486 × 0.8097 = 0.1203\n",
      "\\n  Subset: Division='management'\n",
      "  - Size: 630 samples (0.0420 of total)\n",
      "  - Entropy: 0.5958\n",
      "  - Weighted contribution: 0.0420 × 0.5958 = 0.0250\n",
      "\\n  Subset: Division='IT'\n",
      "  - Size: 1227 samples (0.0818 of total)\n",
      "  - Entropy: 0.7647\n",
      "  - Weighted contribution: 0.0818 × 0.7647 = 0.0626\n",
      "\\n  Subset: Division='product_mng'\n",
      "  - Size: 902 samples (0.0601 of total)\n",
      "  - Entropy: 0.7593\n",
      "  - Weighted contribution: 0.0601 × 0.7593 = 0.0457\n",
      "\\n  Subset: Division='marketing'\n",
      "  - Size: 858 samples (0.0572 of total)\n",
      "  - Entropy: 0.7893\n",
      "  - Weighted contribution: 0.0572 × 0.7893 = 0.0452\n",
      "\\n  Subset: Division='RandD'\n",
      "  - Size: 787 samples (0.0525 of total)\n",
      "  - Entropy: 0.6191\n",
      "  - Weighted contribution: 0.0525 × 0.6191 = 0.0325\n",
      "\\n4. WEIGHTED AVERAGE ENTROPY: 0.7874\n",
      "\\n5. INFORMATION GAIN CALCULATION:\n",
      "   Information Gain = Original Entropy - Weighted Average Entropy\n",
      "   Information Gain = 0.7918 - 0.7874\n",
      "   Information Gain = 0.0045\n",
      "   Information Gain is 0.0045 for Division column\n",
      "   The higher the Information Gain, the better the feature is for decision tree splitting.\n",
      "\\n================================================================================\n"
     ]
    }
   ],
   "source": [
    "# INFORMATION GAIN CALCULATION FOR DIVISION COLUMN\n",
    "# =================================================\n",
    "# Information Gain measures how much information a feature provides about the target variable.\n",
    "# It quantifies the reduction in entropy achieved by splitting the dataset on a particular feature.\n",
    "# Formula: Information Gain = Entropy(Parent) - Weighted Average of Entropy(Children)\n",
    "\n",
    "def calculate_information_gain(data, feature_column, target_column):\n",
    "    \"\"\"\n",
    "    Calculate Information Gain for a given feature column\n",
    "    \n",
    "    Steps:\n",
    "    1. Calculate the original entropy of the target variable (baseline)\n",
    "    2. Split the data based on unique values in the feature column\n",
    "    3. For each subset, calculate entropy of the target variable\n",
    "    4. Calculate weighted average entropy of all subsets\n",
    "    5. Information Gain = Original Entropy - Weighted Average Entropy\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Calculate original entropy (baseline entropy of target variable)\n",
    "    print(f\"=== INFORMATION GAIN ANALYSIS FOR '{feature_column.upper()}' COLUMN ===\\n\")\n",
    "    \n",
    "    original_entropy = calculate_entropy(data, target_column)\n",
    "    print(f\"\\n1. BASELINE ENTROPY of '{target_column}' column: {original_entropy:.4f}\")\n",
    "    \n",
    "    # Step 2: Get unique values in the feature column to split on\n",
    "    unique_values = data[feature_column].unique()\n",
    "    print(f\"\\n2. UNIQUE VALUES in '{feature_column}' column: {unique_values}\")\n",
    "    \n",
    "    # Step 3: Calculate entropy for each subset created by splitting on feature column\n",
    "    print(f\"\\n3. CALCULATING ENTROPY FOR EACH SUBSET:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    total_samples = len(data)\n",
    "    weighted_entropy = 0\n",
    "    \n",
    "    for value in unique_values:\n",
    "        # Create subset of data for this feature value\n",
    "        subset = data[data[feature_column] == value]\n",
    "        subset_size = len(subset)\n",
    "        \n",
    "        # Calculate entropy for this subset\n",
    "        subset_entropy = calculate_entropy(subset, target_column)\n",
    "        \n",
    "        # Calculate weight (proportion of total data this subset represents)\n",
    "        weight = subset_size / total_samples\n",
    "        \n",
    "        # Add to weighted entropy calculation\n",
    "        weighted_entropy += weight * subset_entropy\n",
    "        \n",
    "        print(f\"\\\\n  Subset: {feature_column}='{value}'\")\n",
    "        print(f\"  - Size: {subset_size} samples ({weight:.4f} of total)\")\n",
    "        print(f\"  - Entropy: {subset_entropy:.4f}\")\n",
    "        print(f\"  - Weighted contribution: {weight:.4f} × {subset_entropy:.4f} = {weight * subset_entropy:.4f}\")\n",
    "    \n",
    "    # Step 4: Calculate Information Gain\n",
    "    information_gain = original_entropy - weighted_entropy\n",
    "    \n",
    "    print(f\"\\\\n4. WEIGHTED AVERAGE ENTROPY: {weighted_entropy:.4f}\")\n",
    "    print(f\"\\\\n5. INFORMATION GAIN CALCULATION:\")\n",
    "    print(f\"   Information Gain = Original Entropy - Weighted Average Entropy\")\n",
    "    print(f\"   Information Gain = {original_entropy:.4f} - {weighted_entropy:.4f}\")\n",
    "    print(f\"   Information Gain = {information_gain:.4f}\")\n",
    "    \n",
    "   \n",
    "    print(f\"   Information Gain is {information_gain:.4f} for {feature_column} column\")\n",
    "    print(f\"   The higher the Information Gain, the better the feature is for decision tree splitting.\")\n",
    "    return information_gain\n",
    "\n",
    "# Calculate Information Gain for Division column\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "division_info_gain = calculate_information_gain(df, 'Division', 'left')\n",
    "print(\"\\\\n\" + \"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
